{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "CNNs_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3mZ7grqFzAyv",
        "0ifPdkgXzAy5"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shlior7/DL-Assignment-2/blob/master/CNNs_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6qnplSszAyd"
      },
      "source": [
        "$$\n",
        "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
        "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
        "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
        "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
        "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
        "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
        "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
        "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
        "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
        "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
        "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
        "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
        "$$\n",
        "# Convolutional Architectures\n",
        "<a id=part3></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j1JribAzAye"
      },
      "source": [
        "In this assignment we will explore convolution networks and the effects of their architecture on accuracy. We'll implement a common block-based deep CNN pattern and we'll perform various experiments on it while varying the architecture. Then we'll implement our own custom architecture to see whether we can get high classification results on CIFAR-10.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyFzIWOFbul1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef00d97-4b09-4d10-8e6d-e5f621eb2f7e"
      },
      "source": [
        "!pip install tqdm==4.17.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm==4.17.1 in /usr/local/lib/python3.7/dist-packages (4.17.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T14:09:42.052063Z",
          "start_time": "2021-05-21T14:09:41.463129Z"
        },
        "id": "4xnzpBADzAyf"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import unittest\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as tvtf\n",
        "\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "seed = 42\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "test = unittest.TestCase()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN_lkkNbzyEm",
        "outputId": "5ad1cab5-3829-41b9-d5bf-76107a75f7d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "#change this\n",
        "%cd /content/drive/MyDrive/Deep Learning/Assignment 2/CNN\n",
        "from utils import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Deep Learning/Assignment 2/CNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B4jeJXYzAyg"
      },
      "source": [
        "## Convolutional layers and networks\n",
        "<a id=part3_1></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9oPN2W9zAyh"
      },
      "source": [
        "Convolutional layers are the most essential building blocks of the state of the art deep learning image classification models and also play an important role in many other tasks.\n",
        "As we already saw, convolutional layers operate on and produce volumes (3D tensors) of activations.\n",
        "\n",
        "\n",
        "One way to interpret convolutional layers is as a collection of 3D learnable filters,\n",
        "each of which operates on a small spatial region of the input volume.\n",
        "Each filter is convolved with the input volume (\"slides over it\"),\n",
        "and a dot product is computed at each location followed by a non-linearity which produces one activation.\n",
        "All these activations produce a 2D plane known as a **feature map**.\n",
        "Multiple feature maps (one for each filter) comprise the output volume.\n",
        "\n",
        "![picture](https://sci2lab.github.io/ml_tutorial/images/cnn_convolution_3.png)\n",
        "\n",
        "A crucial property of convolutional layers is their translation invariance,\n",
        "i.e. their ability to detect features regardelss of their spatial location in the input.\n",
        "\n",
        "Convolutional network architectures usually follow a pattern basic repeating blocks: one or more convolution layers, each followed by a non-linearity (generally ReLU) and then a pooling layer to reduce spatial dimensions. Usually, the number of convolutional filters increases the deeper they are in the network.\n",
        "These layers are meant to extract features from the input.\n",
        "Then, one or more fully-connected layers is used to combine the extracted features into the required number of output class scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4KnvGoHzAyi"
      },
      "source": [
        "## Building convolutional networks with PyTorch\n",
        "<a id=part3_2></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CTnzs2fzAyi"
      },
      "source": [
        "PyTorch provides all the basic building blocks needed for creating a convolutional arcitecture within the [`torch.nn`](https://pytorch.org/docs/stable/nn.html) package.\n",
        "Let's use them to create a basic convolutional network with the following architecture pattern:\n",
        "\n",
        "    [(CONV -> ReLU)*P -> MaxPool]*(N/P) -> (Linear -> ReLU)*M -> Linear\n",
        "\n",
        "Here $N$ is the total number of convolutional layers,\n",
        "$P$ specifies how many convolutions to perform before each pooling layer\n",
        "and $M$ specifies the number of hidden fully-connected layers before the final output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzpHd8FRzAyj"
      },
      "source": [
        "**TODO**: Complete the implementaion of the `ConvClassifier` class in the `utils/models.py` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T14:09:44.195067Z",
          "start_time": "2021-05-21T14:09:42.053490Z"
        },
        "id": "7fHSjIgZzAyj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "4d02a504-e1d0-4354-f143-4a1601c49796"
      },
      "source": [
        "from  utils import models\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "net = models.ConvClassifier((3,100,100), 10, filters=[32]*4, pool_every=2, hidden_dims=[100]*2).to(device)\n",
        "print(net)\n",
        "\n",
        "test_image = torch.randint(low=0, high=256, size=(3, 100, 100), dtype=torch.float).to(device)\n",
        "test_out = net(test_image.unsqueeze(0))\n",
        "print('out =', test_out)\n",
        "\n",
        "expected_out = torch.load('tests/assets/expected_conv_out.pt').to(device)\n",
        "test.assertLess(torch.norm(test_out - expected_out).item(), 1e-5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f1a7296a5ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m  \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Deep Learning/Assignment 2/CNN/utils/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxavier_uniform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxavier_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.blocks'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G0j_dWVzAym"
      },
      "source": [
        "**Note about running on GPUs**.\n",
        "\n",
        "Notice how we called `.to(device)` on **both** the model and the input tensor.\n",
        "Here the `device` is a `torch.device` object that we created above. If an nvidia GPU is available on the machine you're running this on, the `device` will be `'cuda'`. When you run `.to(device)` on a model, it recursively goes over all the model parameter tensors and copies their memory to the GPU. Similarly, calling `.to(device)` on the input image also copies it.\n",
        "\n",
        "In order to train on a GPU, you need to make sure to move **all** your tensors to it. You'll get errors if you try to mix CPU and GPU tensors in a computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T14:09:44.212898Z",
          "start_time": "2021-05-21T14:09:44.200880Z"
        },
        "id": "BzKXu747zAym"
      },
      "source": [
        "print(f'This notebook is running with device={device}')\n",
        "print(f'The model parameter tensors are therefore also on device={next(net.parameters()).device}')\n",
        "print(f'The test image is therefore also on device={test_image.device}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U2TEQR9zAyn"
      },
      "source": [
        "Let's load CIFAR-10 again to use as our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-21T14:09:45.612193Z",
          "start_time": "2021-05-21T14:09:44.329274Z"
        },
        "id": "EGrD4rpqzAyn"
      },
      "source": [
        "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
        "ds_train = torchvision.datasets.CIFAR10(root=data_dir, download=True, train=True, transform=tvtf.ToTensor())\n",
        "ds_test = torchvision.datasets.CIFAR10(root=data_dir, download=True, train=False, transform=tvtf.ToTensor())\n",
        "\n",
        "print(f'Train: {len(ds_train)} samples')\n",
        "print(f'Test: {len(ds_test)} samples')\n",
        "\n",
        "x0,_ = ds_train[0]\n",
        "in_size = x0.shape\n",
        "num_classes = 10\n",
        "print('input image size =', in_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFPzUFbEzAyo"
      },
      "source": [
        "Now as usual, as a sanity test let's make sure we can overfit a tiny dataset with our model. But first we need to adapt our `Trainer` for PyTorch models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clMKyM1mzAyo"
      },
      "source": [
        "**TODO**: Complete the implementaion of the `TorchTrainer` class in the `utils/training.py` module. \n",
        "You should implement the funcitons:\n",
        "* fit (...)\n",
        "* train_batch(...)\n",
        "* test_batch(...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-18T14:25:53.978415Z",
          "start_time": "2021-05-18T14:25:52.717438Z"
        },
        "id": "WwQp63WNzAyp"
      },
      "source": [
        "import utils.training as training\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Define a tiny part of the CIFAR-10 dataset to overfit it\n",
        "batch_size = 2\n",
        "max_batches = 25\n",
        "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=False)\n",
        "\n",
        "# Create model, loss and optimizer instances\n",
        "model = models.ConvClassifier(in_size, num_classes, filters=[32], pool_every=1, hidden_dims=[100])\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9,)\n",
        "\n",
        "# Use TorchTrainer to run only the training loop a few times.\n",
        "trainer = training.TorchTrainer(model, loss_fn, optimizer, device)\n",
        "best_acc = 0\n",
        "for i in range(22):\n",
        "    res = trainer.train_epoch(dl_train, max_batches=max_batches, verbose=(i%2==0))\n",
        "    best_acc = res.accuracy if res.accuracy > best_acc else best_acc\n",
        "    \n",
        "# Test overfitting\n",
        "test.assertGreaterEqual(best_acc, 95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1BR4wBfzAyq"
      },
      "source": [
        "## Experimenting with model architectures\n",
        "<a id=part3_3></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdz6pN5SzAyq"
      },
      "source": [
        "You will now perform a series of experiments that train various model configurations on a much larger part of the CIFAR-10 dataset.\n",
        "\n",
        "To perform the experiments, you'll need to use a machine with a GPU since training time might be too long otherwise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSGDZ2kfzAyq"
      },
      "source": [
        "### General notes for running experiments\n",
        "\n",
        "- It's important to give each experiment run a name as specified by the notebook instructions later on. The each run has a `run_name` parameter that will also be the name of the results file which this notebook will expect to load.\n",
        "\n",
        "- You will implement the code to run the experiments in the `utils/experiments.py` module. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bConnF6zAyr"
      },
      "source": [
        "### Experiment 1 - Network depth and number of filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT8HrA5tzAyr"
      },
      "source": [
        "In this part we will test some different architecture configurations based on our `ConvClassifier`.\n",
        "Specifically, we want to try different depths and number of features to see the effects these parameters have on the model's performance.\n",
        "\n",
        "To do this, we'll define two extra hyperparameters for our model, `K` (`filters_per_layer`) and `L` (`layers_per_block`).\n",
        "- `K` is a list, containing the number of filters we want to have in our conv layers.\n",
        "- `L` is the number of consecutive layers with the same number of filters to use.\n",
        "\n",
        "For example, if `K=[32, 64]` and `L=2` it means we want two conv layers with 32 filters followed by two conv layers with 64 filters. The feature-extraction part of our model will therefore be:\n",
        "\n",
        "    Conv(X,32)->ReLu->Conv(32,32)->ReLU->MaxPool->Conv(32,64)->ReLU->Conv(64,64)->ReLU->MaxPool\n",
        "    \n",
        "We'll try various values of the `K` and `L` parameters in combination and see how each architecture trains. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghk8kzI1zAys"
      },
      "source": [
        "First we need to write some code to run the experiment.\n",
        "\n",
        "**TODO**:\n",
        "1. Implement the `run_experiment()` function in the `utils/experiments.py` module.\n",
        "1. If you haven't done so already, it would be an excellent idea to implement the **early stopping** feature of the `Trainer` class.\n",
        "\n",
        "The following block tests that your implementation works. It's also meant to show you that each experiment run creates a result file containing the parameters to reproduce and the `FitResult` object for plotting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-18T15:19:56.784156Z",
          "start_time": "2021-05-18T15:18:04.863342Z"
        },
        "scrolled": true,
        "id": "2wqC6b6ozAyt"
      },
      "source": [
        "import utils.experiments as experiments\n",
        "from utils.experiments import load_experiment\n",
        "from utils.plot import plot_fit\n",
        "\n",
        "# Test experiment1 implementation on a few data samples and with a small model\n",
        "experiments.run_experiment('test_run', seed=seed, bs_train=50, batches=10, epochs=10, early_stopping=5,\n",
        "                           filters_per_layer=[32], layers_per_block=1, pool_every=1, hidden_dims=[100])\n",
        "\n",
        "# There should now be a file 'test_run.json' in your `results/` folder.\n",
        "# We can use it to load the results of the experiment.\n",
        "cfg, fit_res = load_experiment('results/test_run.json')\n",
        "_, _ = plot_fit(fit_res)\n",
        "\n",
        "# And `cfg` contains the exact parameters to reproduce it\n",
        "print('experiment config: ', cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3InklPTnzAyu"
      },
      "source": [
        "We'll use the following function to load multiple experiment results and plot them together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-18T17:18:52.318106Z",
          "start_time": "2021-05-18T17:18:52.306885Z"
        },
        "id": "mZQXL0lYzAyv"
      },
      "source": [
        "def plot_exp_results(filename_pattern, results_dir='results'):\n",
        "    fig = None\n",
        "    result_files = glob.glob(os.path.join(results_dir, filename_pattern))\n",
        "    result_files.sort()\n",
        "    if len(result_files) == 0:\n",
        "        print(f'No results found for pattern {filename_pattern}.', file=sys.stderr)\n",
        "        return\n",
        "    for filepath in result_files:\n",
        "        m = re.match('exp\\d_(\\d_)?(.*)\\.json', os.path.basename(filepath))\n",
        "        cfg, fit_res = load_experiment(filepath)\n",
        "        fig, axes = plot_fit(fit_res, fig, legend=m[2],log_loss=True)\n",
        "    del cfg['filters_per_layer']\n",
        "    del cfg['layers_per_block']\n",
        "    print('common config: ', cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mZ7grqFzAyv"
      },
      "source": [
        "#### Experiment 1.1: Varying the network depth (`L`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OachjQHYzAyv"
      },
      "source": [
        "First, we'll test the effect of the network depth on training.\n",
        "\n",
        "**Configuratons**:\n",
        "- `K=32` fixed, with `L=2,4,8,16` varying per run\n",
        "- `K=64` fixed, with `L=2,4,8,16` varying per run\n",
        "\n",
        "So 8 different runs in total.\n",
        "\n",
        "**Naming runs**:\n",
        "Each run should be named `exp1_1_K{}_L{}` where the braces are placeholders for the values. For example, the first run should be named `exp1_1_K32_L2`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyoBdWwGzAyw"
      },
      "source": [
        "**TODO**: Run the experiment on the above configuration. Make sure the result file names are as expected. Use the following blocks to display the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySbF1l1GC5ua"
      },
      "source": [
        "import utils.experiments as experiments\n",
        "from utils.experiments import load_experiment\n",
        "from utils.plot import plot_fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7qJWKv1zAyw"
      },
      "source": [
        "for l in [2,4,8,16]:\n",
        "    # Test experiment1 implementation on a few data samples and with a small model\n",
        "    experiments.run_experiment(f'exp1_1_K32_L{l}',\n",
        "                               seed=seed,\n",
        "                               bs_train=50,\n",
        "                               batches=10000,\n",
        "                               epochs=30, \n",
        "                               early_stopping=5,\n",
        "                               reg=2e-3,\n",
        "                               lr=1e-3,\n",
        "                               filters_per_layer=[32],\n",
        "                               layers_per_block=l,\n",
        "                               pool_every=4,\n",
        "                               hidden_dims=[100, 100])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-19T09:50:52.197168Z",
          "start_time": "2021-05-19T09:50:50.932669Z"
        },
        "id": "oX7ikonzzAyz"
      },
      "source": [
        "plot_exp_results('exp1_1_K32*.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-19T11:57:53.070856Z",
          "start_time": "2021-05-19T09:50:52.198830Z"
        },
        "id": "WwqKKFRvzAy0"
      },
      "source": [
        "for l in [2,4,8,16]:\n",
        "    # Test experiment1 implementation on a few data samples and with a small model\n",
        "    experiments.run_experiment(f'exp1_1_K64_L{l}',\n",
        "                               seed=seed,\n",
        "                               bs_train=50,\n",
        "                               batches=10000,\n",
        "                               epochs=30, \n",
        "                               early_stopping=5,\n",
        "                               reg=2e-3,\n",
        "                               lr=1e-3,\n",
        "                               filters_per_layer=[64],\n",
        "                               layers_per_block=l,\n",
        "                               pool_every=4,\n",
        "                               hidden_dims=[100, 100])\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-19T11:57:55.454384Z",
          "start_time": "2021-05-19T11:57:54.263801Z"
        },
        "id": "ra1Npp-tzAy3"
      },
      "source": [
        "plot_exp_results('exp1_1_K64*.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQtg-zdTzAy3"
      },
      "source": [
        "### Question 1 \n",
        "\n",
        "Analyze your results from experiment 1.1. In particular,\n",
        "1.  Explain the effect of depth on the accuracy. What depth produces the best results and why do you think that's the case?\n",
        "1. Were there values of `L` for which the network wasn't trainable? what causes this? Suggest two things which may be done to resolve it at least partially.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiwwJwU0zAy4"
      },
      "source": [
        "**ANSWER**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqkLruj1zAy4"
      },
      "source": [
        "**Extra Points:** \n",
        "\n",
        "Try solve the problem we saw, using your suggestions. implement it in utils/model.py/YourCodeNet and run again (one of the) experiments where the model wasn't trained to see if the problem have solved).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXRNf6pizAy4"
      },
      "source": [
        "###### Extra Points ######\n",
        "# run again (one of the) experiments where the model wasn't trained at all,\n",
        "# but use YourCodeNet to see if your implemented suggestions fixed the problem.\n",
        "# set ycn=True when you call experiments.run_experiment(...)\n",
        "# ====== YOUR CODE: ======\n",
        "# it is recommended to use loops in order to run all experiments.\n",
        "# ========================"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ifPdkgXzAy5"
      },
      "source": [
        "#### Experiment 1.2: Varying the number of filters per layer (`K`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejFHjzCXzAy5"
      },
      "source": [
        "Now we'll test the effect of the number of convolutional filters in each layer.\n",
        "\n",
        "**Configuratons**:\n",
        "- `L=2` fixed, with `K=[32],[64],[128],[256]` varying per run.\n",
        "- `L=4` fixed, with `K=[32],[64],[128],[256]` varying per run.\n",
        "- `L=8` fixed, with `K=[32],[64],[128],[256]` varying per run.\n",
        "\n",
        "So 12 different runs in total. To clarify, each run `K` takes the value of a list with a single element.\n",
        "\n",
        "**Naming runs**:\n",
        "Each run should be named `exp1_2_L{}_K{}` where the braces are placeholders for the values. For example, the first run should be named `exp1_2_L2_K32`. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ZJaH1gzAy6"
      },
      "source": [
        "**TODO**: Run the experiment on the above configuration. Make sure the result file names are as expected. Use the following blocks to display the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-19T16:58:11.999679Z",
          "start_time": "2021-05-19T11:57:55.455927Z"
        },
        "id": "yM0e61MyzAy6"
      },
      "source": [
        "for l in [2,4,8]:\n",
        "    for k in [32,64,128,256]:\n",
        "        # Test experiment1 implementation on a few data samples and with a small model\n",
        "        experiments.run_experiment(f'exp1_2_L{l}_K{k}',\n",
        "                                   seed=seed,\n",
        "                                   bs_train=50,\n",
        "                                   batches=10000,\n",
        "                                   epochs=30, \n",
        "                                   early_stopping=5,\n",
        "                                   reg=2e-3,\n",
        "                                   lr=1e-3,\n",
        "                                   filters_per_layer=[k],\n",
        "                                   layers_per_block=l,\n",
        "                                   pool_every=4, \n",
        "                                   hidden_dims=[100, 100])\n",
        "       \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-19T16:58:13.345082Z",
          "start_time": "2021-05-19T16:58:12.001036Z"
        },
        "id": "FvMTW-klzAy8"
      },
      "source": [
        "plot_exp_results('exp1_2_L2*.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-19T16:58:14.649782Z",
          "start_time": "2021-05-19T16:58:13.346304Z"
        },
        "id": "_SLZdugAzAy8"
      },
      "source": [
        "plot_exp_results('exp1_2_L4*.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-19T16:58:15.930491Z",
          "start_time": "2021-05-19T16:58:14.651206Z"
        },
        "id": "PeYo3NJEzAy9"
      },
      "source": [
        "plot_exp_results('exp1_2_L8*.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbHi8AyszAy9"
      },
      "source": [
        "### Question 2 \n",
        "\n",
        "Analyze your results from experiment 1.2. In particular, compare to the results of experiment 1.1. For a spesific value of L, how the preformance change with respect to K? Does we saw the same phenomena in 1.1 for a spresific value of K?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RCjOSrozAy9"
      },
      "source": [
        "**ANSWER**:"
      ]
    }
  ]
}